# -*- coding: utf-8 -*-
"""Laboratorio_02.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ogbfuZIp6Kuqie4ETU21iZfRFfJZBg24

Importación de Librerías
"""

# Commented out IPython magic to ensure Python compatibility.
import os
import numpy as np
from matplotlib import pyplot
# %matplotlib inline
import pandas as pd

"""#Regresión Multivariable

Importación de DataSet de Google Drive, limpieza del dataset y visualización de datos
"""

from google.colab import drive
drive.mount("/content/drive")
import pandas as pd
data = pd.read_csv('/content/drive/MyDrive/machine learning/datasets/Player_Attributes.csv', delimiter=',')
data = data.dropna()
data.info()

"""Cargamos las variables x, y y m demás de tomar datos del mismo data set para predicciones"""

X = data.iloc[:15000, [5,9,10,11,12,13,14,15,16,17]]
y = data.iloc[:15000, 4]
m = y.size

X_predic = data.iloc[15000:15100, [5,9,10,11,12,13,14,15,16,17]]
y_predic = data.iloc[15000:15100, 4]
m_predic = y_predic.size

"""Visualización de datos"""

print(X)
print('------------------------------------------------------------------------------')
print(y)
print(m)
print('------------------------------------------------------------------------------')
print('------------------------------------------------------------------------------')
print(X_predic)
print('------------------------------------------------------------------------------')
print(y_predic)
print(m_predic)

"""Funcion para sacar X nomalizada, mu(Media calculada), sigma(desviación estandar)"""

def  featureNormalize(X):
    X_norm = X.copy()
    mu = np.zeros(X.shape[1])
    sigma = np.zeros(X.shape[1])
    mu = np.mean(X, axis = 0)
    sigma = np.std(X, axis = 0)
    X_norm = (X - mu) / sigma

    return X_norm, mu, sigma

"""Mostramos media, desviación estandar y X normalizada"""

X_norm, mu, sigma = featureNormalize(X)

print('Media calculada:\n', mu)
print('Desviación estandar calculada:\n', sigma)
print(X_norm)

"""Agregamos la columna de 1 x^0"""

X = np.concatenate([np.ones((m, 1)), X_norm], axis=1)

"""Funcion que calcula el Costo J"""

def computeCostMulti(X, y, theta):
    J = 0
    J = (1/(2 * m)) * np.sum(np.square(np.dot(X, theta) - y))
    return J

"""Funcion que calcula las Theta y el historial de costo"""

def gradientDescentMulti(X, y, theta, alpha, num_iters):
    theta = theta.copy()
    J_history = []
    for i in range(num_iters):
        theta = theta - (alpha / m) * (np.dot(X, theta) - y).dot(X)
        J_history.append(computeCostMulti(X, y, theta))
    return theta, J_history

"""Calculo de Theta y el costo menor"""

alpha = 0.001
num_iters = 5000

theta = np.zeros(11)
theta, J_history = gradientDescentMulti(X, y, theta, alpha, num_iters)
print(J_history[-1])

pyplot.plot(np.arange(len(J_history)), J_history, lw=2)
pyplot.xlabel('Numero de iteraciones')
pyplot.ylabel('Costo J')
pyplot.title('Convergencia del Descenso por el Gradiente')
pyplot.show()

"""Calculo de predicciones"""

X_norm, mu, sigma = featureNormalize(X_predic)
X_regresion = np.concatenate([np.ones((m_predic, 1)), X_norm], axis=1)
for i in range(m_predic):
  X_array = np.array(X_regresion[i])
  Prediccion = np.dot(X_array, theta)
  Error = y_predic.iloc[i] - Prediccion
  print('La predicción es: ',Prediccion,'El valor original es de: ', y_predic.iloc[i],' y el error de: ', Error)

"""#Regresión Polinomial

Importación de DataSet de Google Drive, limpieza del dataset y visualización de datos
"""

from google.colab import drive
drive.mount("/content/drive")
import pandas as pd
data = pd.read_csv('/content/drive/MyDrive/machine learning/datasets/Player_Attributes.csv', delimiter=',')
data = data.dropna()
data.info()

"""Cargamos las variables x, y y m demás de tomar datos del mismo data set para predicciones"""

X = data.iloc[:15000, [5,9,10,11,12,13,14,15,16,17]]
y = data.iloc[:15000, 4]
m = y.size

X_predic = data.iloc[15000:15100, [5,9,10,11,12,13,14,15,16,17]]
y_predic = data.iloc[15000:15100, 4]
m_predic = y_predic.size

"""Visualización de datos"""

print(X)
print('------------------------------------------------------------------------------')
print(y)
print(m)
print('------------------------------------------------------------------------------')
print('------------------------------------------------------------------------------')
print(X_predic)
print('------------------------------------------------------------------------------')
print(y_predic)
print(m_predic)

"""Concatenamos X con X al cuadrado"""

X = np.concatenate([X, X * X], axis=1)

"""Normalizacion de datos por funcion"""

def  featureNormalizeFuncion(X):
    X_norm = X.copy()
    mu = np.zeros(X.shape[1])
    sigma = np.zeros(X.shape[1])

    mu = np.mean(X, axis = 0)
    sigma = np.std(X, axis = 0)
    X_norm = (X - mu) / sigma

    return X_norm, mu, sigma

"""Normalización y visualización de resultados"""

X_norm, mu, sigma = featureNormalizeFuncion(X)

print(X)
print('Media calculada:', mu)
print('Desviación estandar calculada:', sigma)
print(X_norm)

"""Agregamos la columna de 1 a x"""

X = np.concatenate([np.ones((m, 1)), X_norm], axis=1)

"""Funcion que calcula el Costo J"""

def computeCostMulti(X, y, theta):
    J = 0
    J = (1/(2 * m)) * np.sum(np.square(np.dot(X, theta) - y))
    return J

"""Funcion que calcula las Theta y el historial de costo"""

def gradientDescentPoly(X, y, theta, alpha, num_iters):
    theta = theta.copy()
    J_history = []

    for i in range(num_iters):
        theta = theta - (alpha / m) * (np.dot(X, theta) - y).dot(X)
        J_history.append(computeCostMulti(X, y, theta))

    return theta, J_history

"""Calculo de Theta y el costo menor"""

alpha = 0.001
num_iters = 5000

theta = np.zeros(21)
theta, J_history = gradientDescentPoly(X, y, theta, alpha, num_iters)

pyplot.plot(np.arange(len(J_history)), J_history, lw=2)
pyplot.xlabel('Numero de iteraciones')
pyplot.ylabel('Costo J')

print(J_history[-1])

"""Calculo de predicciones"""

X_predic = np.concatenate([X_predic, X_predic * X_predic], axis=1)
X_norm, mu, sigma = featureNormalize(X_predic)
X_regresion = np.concatenate([np.ones((m_predic, 1)), X_norm], axis=1)
for i in range(m_predic):
  X_array = np.array(X_regresion[i])
  Prediccion = np.dot(X_array, theta)
  Error = y_predic.iloc[i] - Prediccion
  print('La predicción es: ',Prediccion,'El valor original es de: ', y_predic.iloc[i],' y el error de: ', Error)

"""#Ecuacion de la normal

Importación de DataSet de Google Drive, limpieza del dataset y visualización de datos
"""

from google.colab import drive
drive.mount("/content/drive")
import pandas as pd
data = pd.read_csv('/content/drive/MyDrive/machine learning/datasets/Player_Attributes.csv', delimiter=',')
data = data.dropna()
data.info()

"""Cargamos las variables x, y y m demás de tomar datos del mismo data set para predicciones"""

X = data.iloc[:15000, [5,9,10,11,12,13,14,15,16,17]]
y = data.iloc[:15000, 4]
m = y.size

X_predic = data.iloc[15000:15100, [5,9,10,11,12,13,14,15,16,17]]
y_predic = data.iloc[15000:15100, 4]
m_predic = y_predic.size

"""Visualización de datos"""

print(X)
print('------------------------------------------------------------------------------')
print(y)
print(m)
print('------------------------------------------------------------------------------')
print('------------------------------------------------------------------------------')
print(X_predic)
print('------------------------------------------------------------------------------')
print(y_predic)
print(m_predic)

"""Agregamos la columna de 1 x^0"""

X = np.concatenate([np.ones((m, 1)), X], axis=1)

"""Funcion para conseguir Theta mediante la ecuación de la Normal"""

def normalEqn(X, y):
    theta = np.zeros(X.shape[1])
    theta = np.dot(np.dot(np.linalg.inv(np.dot(X.T,X)),X.T),y)
    return theta

"""Calculo de Theta y el costo"""

theta = normalEqn(X, y)
print('theta: ',theta)
print('------------------------------------------------------------------------')
j=computeCostMulti(X, y, theta)
print('Costo: ',j)

"""Calculo de predicciones"""

X_regresion = np.concatenate([np.ones((m_predic, 1)), X_predic], axis=1)
for i in range(m_predic):
  X_array = np.array(X_regresion[i])
  Prediccion = np.dot(X_array, theta)
  Error = y_predic.iloc[i] - Prediccion
  print('La predicción es: ',Prediccion,'El valor original es de: ', y_predic.iloc[i],' y el error de: ', Error)